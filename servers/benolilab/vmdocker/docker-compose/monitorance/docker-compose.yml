name: monitorance-docker
secrets:    
    watchtower_discord_hook:
        file: ./secrets/.watchtower_discord_hook
    zfs_backup_ssh_key:
        file: ./secrets/.zfs_backup_ssh_key
    zfs_backup_ssh_user:
        file: ./secrets/.zfs_backup_ssh_user
    zfs_backup_ssh_host:
        file: ./secrets/.zfs_backup_ssh_host    
x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"
services:
    portainer:
        container_name: portainer
        image: "portainer/portainer-ce:alpine"
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.10
        ports:
          - "9443:9443/tcp"
        restart: always
        volumes:
          - "/var/run/docker.sock:/var/run/docker.sock"
          - "portainer_data:/data"
        healthcheck:
              test: ["CMD-SHELL", "wget --no-check-certificate --spider -q https://localhost:9443/api/status || exit 1"]
              interval: 1m30s
              timeout: 30s
              retries: 5
        labels:
            description: "Portainer is a web-based Docker management system that provides a convenient graphical user interface (GUI). It lets you take charge of your containers, images, volumes, and other resources, without memorizing long terminal commands."
            com.centurylinklabs.watchtower.enable: "true"
    watchtower:
        container_name: watchtower
        image: containrrr/watchtower
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.11
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock
        restart: unless-stopped
        environment:
            WATCHTOWER_CLEANUP: true
            WATCHTOWER_DEBUG: true
            WATCHTOWER_ROLLING_RESTART: true
            WATCHTOWER_LABEL_ENABLE: true
            WATCHTOWER_SCHEDULE: 0 0 9 * * 5
            WATCHTOWER_NOTIFICATION_REPORT: true
            WATCHTOWER_NOTIFICATION_URL: /run/secrets/watchtower_discord_hook
            WATCHTOWER_NOTIFICATION_TEMPLATE: |
                {{- if .Report -}}
                    {{- with .Report -}}
                {{len .Scanned}} Scanned, {{len .Updated}} Updated, {{len .Failed}} Failed
                    {{- range .Updated}}
                - {{.Name}} ({{.ImageName}}): {{.CurrentImageID.ShortID}} updated to {{.LatestImageID.ShortID}}
                    {{- end -}}
                    {{- range .Fresh}}
                - {{.Name}} ({{.ImageName}}): {{.State}}
                    {{- end -}}
                    {{- range .Skipped}}
                - {{.Name}} ({{.ImageName}}): {{.State}}: {{.Error}}
                    {{- end -}}
                    {{- range .Failed}}
                - {{.Name}} ({{.ImageName}}): {{.State}}: {{.Error}}
                    {{- end -}}
                    {{- end -}}
                {{- else -}}
                    {{range .Entries -}}{{.Message}}{{"\n"}}{{- end -}}
                {{- end -}}
        secrets:
            - watchtower_discord_hook
        healthcheck:
              test: ["CMD", "/watchtower", "--health-check"]
              interval: 1m30s
              timeout: 10s
              retries: 3
              start_period: 40s
        labels:
            description: "Watchtower is an application that will monitor your running Docker containers and watch for changes to the images that those containers were originally started from."
            com.centurylinklabs.watchtower.enable: "true"
    uptime-kuma:
        container_name: uptime-kuma
        image: louislam/uptime-kuma:1
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.12
        volumes:
            - uptime_kuma_data:/app/data
            - /var/run/docker.sock:/var/run/docker.sock
        ports:
            # <Host Port>:<Container Port>
            - 3001:3001
        restart: unless-stopped
        healthcheck:
            test: "curl --connect-timeout 15 --max-time 100 --silent --show-error --fail 'http://localhost:3001/dashboard'"
            interval: 1m
            timeout: 15s
            retries: 3
            start_period: 1m
        labels:
            description: "Uptime Kuma is a self-hosted monitoring tool designed to track the uptime status of websites, applications, or network services."
            com.centurylinklabs.watchtower.enable: "true"
            docker-volume-backup.stop-during-backup: "true"
    volume-backup-wrapper:
        build: ./volume-backup-wrapper
        container_name: volume-backup-wrapper
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.14
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock  # For control
        env_file:
            - ./volume-backup-wrapper/backup.env
        environment:
            DRY_RUN: false
            DISABLE_CRON: false
        restart: unless-stopped
        labels:
            description: "Wrapper container for the offen/docker-volume-backup immage.  It handles special cases where container-logs need to be checked prior to stopping them for backups (e.g. file synching processes that could be happening during a volume backup)."
            # com.docker.backup.restart-policy: {{match-to-docker-compose-restart-policy-value}} # Add this label to containers to store the original docker compose restart policy for applying back to the container after it is restarted after backups
        healthcheck:
          test: ["CMD-SHELL", "/app/scripts/healthcheck.sh"]
          interval: 60s
          timeout: 5s
          retries: 3
          start_period: 10s
    grafana:
        container_name: grafana
        image: grafana/grafana
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.16
        ports:
          - "3002:3000"
        volumes:
          - grafana_data:/var/lib/grafana
        restart: unless-stopped
        labels:
            description: "Grafana is an open-source data visualization and monitoring platform. It allows users to query, visualize, and alert on data from various sources, providing a comprehensive view of system health, application performance, and other metrics through customizable dashboards."
            com.centurylinklabs.watchtower.enable: "true"
            docker-volume-backup.stop-during-backup: "true"
        healthcheck:
          test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
          interval: 30s
          timeout: 10s
          retries: 3
    prometheus:
        container_name: prometheus
        image: prom/prometheus
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.17
        ports:
          - "9090:9090"
        volumes:
          - prometheus_data:/etc/prometheus
          - prometheus_config:/prometheus
        restart: unless-stopped
        labels:
            description: "Prometheus is a popular monitoring and alerting system. You'll need to set it up to collect Docker container metrics, including memory usage."
            com.centurylinklabs.watchtower.enable: "true"
            docker-volume-backup.stop-during-backup: "true"
        healthcheck:
          test: ["CMD-SHELL", "wget -q --spider http://localhost:9090/ || exit 1"]
          interval: 30s
          timeout: 10s
          retries: 3
    cadvisor:
        container_name: cadvisor
        image: gcr.io/cadvisor/cadvisor
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.18
        ports:
          - "8081:8080"
        volumes:
          - /var/run/docker.sock:/var/run/docker.sock
          - /sys:/sys
          - /var/lib/docker/:/var/lib/docker
        restart: unless-stopped
        labels:
            description: "cAdvisor (Container Advisor) is a tool that provides detailed resource usage information for containers. It can be used alongside Prometheus to gather even more granular data."
            com.centurylinklabs.watchtower.enable: "true"
            docker-volume-backup.stop-during-backup: "true"
        healthcheck:
          test: ["CMD-SHELL", "wget -q --spider http://localhost:8080/ || exit 1"]
          interval: 30s
          timeout: 10s
          retries: 3
    node-exporter:
        container_name: node-exporter
        image: prom/node-exporter
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.19
        ports:
          - "9100:9100"
        restart: unless-stopped
        labels:
            description: "Node Exporter tool collects host-level metrics, including CPU, memory, and disk usage, which can be helpful for understanding the overall system resources available to your Docker containers."
            com.centurylinklabs.watchtower.enable: "true"
            docker-volume-backup.stop-during-backup: "true"
        healthcheck:
          test: ["CMD-SHELL", "wget -q --spider http://localhost:9100/metrics || exit 1"]
          interval: 30s
          timeout: 10s
          retries: 3
    zfs-backup:
        build: ./zfs-backup
        container_name: zfs-backup
        logging: *default-logging
        networks:
          server_net:
            ipv4_address: 172.18.0.24
        env_file:
            - ./zfs-backup/zfs-backup.env
        environment:
            DRY_RUN: false
            DISABLE_CRON: false
            ZFS_BACKUP_SSH_KEY: /run/secrets/zfs_backup_ssh_key
            ZFS_BACKUP_SSH_USER: /run/secrets/zfs_backup_ssh_user
            ZFS_BACKUP_SSH_HOST: /run/secrets/zfs_backup_ssh_host
        secrets:
            - zfs_backup_ssh_key
            - zfs_backup_ssh_user
            - zfs_backup_ssh_host
        restart: unless-stopped
        labels:
            description: "Wrapper container for running the ZFS snapshot and backup script on a ZFS pool.  NOTE: This container relies on a zfs_backup.sh and secrets to already exist on the ZFS pool host machine."
            # com.docker.backup.restart-policy: {{match-to-docker-compose-restart-policy-value}} # Add this label to containers to store the original docker compose restart policy for applying back to the container after it is restarted after backups
        healthcheck:
          test: ["CMD-SHELL", "/app/scripts/healthcheck.sh"]
          interval: 60s
          timeout: 5s
          retries: 3
          start_period: 10s
volumes:
    portainer_data:
        name: portainer_data
    uptime_kuma_data:
        name: uptime_kuma_data
    grafana_data:
        name: grafana_data
    prometheus_data:
        name: prometheus_data
    prometheus_config:
        name: prometheus_config
    nginx_proxy_config:
        name: nginx_proxy_config
        external: true # defined in docker-compose/docker-compose.yml
    nginx_proxy_letsencrypt:
        name: nginx_proxy_letsencrypt
        external: true # defined in docker-compose/docker-compose.yml
    nginx_proxy_data:
        name: nginx_proxy_data
        external: true # defined in docker-compose/docker-compose.yml
    adguard_work:
        name: adguard_work
        external: true # defined in docker-compose/docker-compose.yml
    adguard_conf:
        name: adguard_conf
        external: true # defined in docker-compose/docker-compose.yml
    plex_server_config:
        name: plex_server_config
        external: true # defined in docker-compose/docker-compose.yml
    plex_server_transcode:
        name: plex_server_transcode
        external: true # defined in docker-compose/docker-compose.yml
    plex_server_media:
        name: plex_server_media
        external: true # defined in docker-compose/docker-compose.yml
    syncthing_config:
        name: syncthing_config
        external: true # defined in docker-compose/docker-compose.yml
    immich_pgdata:
        external: true # prevent from defining again since volume is defined in immich/docker-compose.yml
    immich_model_cache:
        external: true # prevent from defining again since volume is defined in immich/docker-compose.yml
    immich_redis_data:
        external: true # prevent from defining again since volume is defined in immich/docker-compose.yml
networks:
    server_net:
        name: server_net
        external: true # prevent from defining again since volume is defined in docker-compose/docker-compose.yml